# PhantomBuster Churn Prediction Engine ðŸ‘»

*Unlock the secrets of customer retention with machine learning.* ðŸ”® 

![Python](https://img.shields.io/badge/Python-3.11%2B-blue)

---

## ðŸŽ¯ Problem Statement  
PhantomBusterâ€™s Executive Committee seeks to proactively identify **at-risk customers** and reduce churn by leveraging data-driven insights. This project delivers a predictive model to flag potential churn risks and uncovers actionable strategies to improve retention.

---

## ðŸš€ Features  
- **Predictive Power**: Identifies customers likely to churn with 75%+ AUC-ROC.  
- **Actionable Insights**: Highlights key drivers of churn.  
- **Scalable Pipeline**: End-to-end workflow from EDA to deployment-ready models.  
- **Explainability**: Permutation importance for stakeholder transparency.  

---

## ðŸ“Š Data & Approach  
### Dataset  
- **Customer Subscriptions**: Plan name, plan age, billing period, currency, monthly payment amount, country code. 
- **Product Usage**: Activity day count, support ticket count, day since last login.  
- **Churn Labels**: Churn status (1/0).  

### Technical Pipeline  
1. **Exploratory Data Analysis (EDA)**  
   - Visualized churn patterns and correlations.  
   - Detected class imbalance (~15/16% churn rate).  
   - Identify how to manage missing values.
2. **Feature Engineering**  
   - Encode categorical features (if necessary). 
   - Normalized quantitative features (if necessary).  
   - Impute missing values (if necessary).
3. **Modeling**  
   - Test several binary classification models.  
   - Test different sets of features (Bruteforce).
   - Optimize hyperparameters with Optuna (Bayesian search).  
   - Calibrate model for better probability estimate.
   - Tune positive label threshold.
4. **Evaluation**  
   - **Best Model**: HistGradientBoosing (AUC-ROC: 0.76).  
   - Key features: `DELINQUENCY_DAY_COUNT`, `PLAN_AGE`, `BILLING_PERIOD`.  

---

## ðŸ’¡ Business Impact  
- **Retention Strategies**: Target high-risk customers with personalized incentives.  
- **Executive Action**: Monthly churn risk reports + automated alert system.  

---

## ðŸ“‚ Repository Structure
```
â”œâ”€â”€ README.md                         <- The top-level README for developers using this project.
â”‚
â”œâ”€â”€ TIMELINE.md                       <- The time allocation for the project.
â”‚
â”œâ”€â”€ data
â”‚   â”œâ”€â”€ dataset.csv                   <- The original, immutable data dump.
â”‚   â”œâ”€â”€ train.csv                     <- The subsample of the original dataset used to train the model.
â”‚   â”œâ”€â”€ test.csv                      <- The subsample of the original dataset used to evaluate the final model.
â”‚   â”œâ”€â”€ pred.csv                      <- The predictions obtained doing inference on the test set using the final model.
â”‚   â””â”€â”€ optuna_study.db               <- SQLite databse which store the Optuna metadata concerning hyperparameters tuning.
â”‚
â”œâ”€â”€ models                            <- Trained and serialized models.
â”‚
â”œâ”€â”€ notebooks                         <- Jupyter notebooks. Naming convention is a number (for ordering).
â”‚
â”œâ”€â”€ reports                           <- Generated analysis as HTML, PDF, LaTeX, etc.
â”‚  
â”œâ”€â”€ pyproject.toml                    <- Project configuration file with package metadata for churn_classification_engine and configuration for tools like ruff.
â”‚
â”œâ”€â”€ uv.lock                           <- A cross-platform lockfile that contains exact information about the project's dependencies
â”‚
â”œâ”€â”€ .python-version                   <- Python-version for this project.
â”‚
â””â”€â”€ churn_classification_engine       <- Source code.
    â”œâ”€â”€ __init__.py                   <- Makes churn_classification_engine a Python module.
    â”œâ”€â”€ config.py                     <- Store useful variables and configuration.
    â”œâ”€â”€ data
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ get-data.py               <- Scripts to download data.
    â”‚   â””â”€â”€ split-data.py             <- Code to split the data in train and test sets.
    â””â”€â”€ model                
        â”œâ”€â”€ __init__.py 
        â”œâ”€â”€ hyperparameters-tuning.py <- Code to find the best hyperparameters for selected model.  
        â”œâ”€â”€ train.py                  <- Code to train & calibrate the final model with the train set.          
        â”œâ”€â”€ predict-proba.py          <- Code to get the churn probability of customers in test set.            
        â””â”€â”€ evaluate.py               <- Code to generate an HTML report with main evaluation metrics.

```

---

## ðŸ› ï¸ Installation & Usage 
1. Download project 
```bash
git clone https://github.com/paulsteffen-lab/phantombuster-casestudy.git
```

2. Create virtual environment
```bash
uv sync
```

3. Get data
```bash
uv run churn_classification_engine/data/get-data.py
```

4. Split data
```bash
uv run churn_classification_engine/data/split-data.py
```

5. Hyperparameters tuning (optional)
```bash
uv run churn_classification_engine/model/hyperparameters-tuning.py
```

6. Train the classifier pipeline on the train set
```bash
uv run churn_classification_engine/model/train.py
```

6. Predict churn probability on the test set
```bash
uv run churn_classification_engine/model/predict-proba.py
```

7. Evaluate the prediction
```bash
uv run churn_classification_engine/model/evaluate.py
```